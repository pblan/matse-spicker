\section{Einzelprozessorsysteme}\label{sec:einzelprozessorsysteme}

\begin{defi}{Überlappte Verarbeitung}
    Erstes Ziel war die überlappte Verarbeitung von langsamen und schnellen Hardware-Komponenten. 
    (Verstecken der langsamen Funktionseinheiten)
\end{defi}

\begin{defi}{Überlappter I/O}
    Während des langsamen I/O kann nun gleichzeitig die \enquote{wertvolle} Ressource CPU genutzt werden.
\end{defi}

\subsection{Cache}\label{subsec:cache}

\begin{defi}{Cache}
    \ldots ist ein schneller Speicher mit verhältnismäßig kleiner Speicherkapazität, 
    der zwischen der Zentraleinheit (CPU) und dem Arbeitsspeicher positioniert ist.
\end{defi}

\begin{defi}{Direct Mapped Cache}
    Feste Abbildung der Hauptspeicher-Adressen auf die Cache-Adressen
    \begin{itemize}[$\to$]
        \item Kein assoziativer Speicher nötig
        \item Keine Verdrängungsstrategien nötig
    \end{itemize}
\end{defi}

\begin{defi}{N-way Set Associative Cache}
    N-fache Mengenassoziativität: $N$ Einträge pro Cache-Index \\
    \quad $\to$ $N$ Caches mit direkter Abbildung, die parallel operieren
    ($N$ liegt meist zwischen 2 und 4)\\
    Beispiel: zweifach mengenassoziativer Cache
    \begin{itemize}
        \item Der Cache-Index bestimmt eine \enquote{Menge} von Blöcken im Cache
        \item Die beiden Tags werden parallel verglichen.
        \item Die Daten werden aufgrund des Tagvergleichs selektiert.
    \end{itemize}
\end{defi}

\begin{defi}{Fully Associative Cache}
    
\end{defi}

\begin{defi}{Ersetzungsstrategie}
    \begin{itemize}
        \item Trivial für Direct Mapped Cache
        \item Bei Set Associative oder Fully Associative:
              \begin{itemize}
                  \item Random
                  \item LRU (Least Recently Used) bzw. FIFO
              \end{itemize}
    \end{itemize}
    Zurückschreiben von Daten:
    \begin{itemize}
        \item \underline{Write through:} Die Information wird sowohl in den Cache als auch ins
              Memory zurückgeschrieben.
        \item \underline{Write back:} Die Information wird nur in den Cache geschrieben. Die
              veränderte Zeile wird erst dann ins Memory geschrieben, wenn die
              Cache-Zeile mit Daten aus anderen Hauptspeicheradressen
              überschrieben werden soll.
              \begin{itemize}
                  \item \underline{Vorteil:} Mehrfaches Ändern eines Wertes wird nur im Cache durchgeführt.
                  \item \underline{Nachteil:} Ein Read-Miss kann zu einem Schreiben ins Memory führen.
              \end{itemize}
    \end{itemize}
\end{defi}

\begin{bonus}[Cache]{IBM Power 4}
    
\end{bonus}

\begin{bonus}[Cache]{Intel Itanium}
    
\end{bonus}

\begin{defi}{Cache Miss}
    Ist keine Kopie der Hauptspeicherzelle a im Cache abgelegt, so 
    \begin{itemize}
        \item greift die CPU auf den Arbeitsspeicher zu,
        \item lädt das Datum in den Cache und
        \item lädt das Datum gleichzeitig in die CPU.
    \end{itemize}
\end{defi}

\begin{defi}{Reduzierung der Cache Miss Rate}
    \begin{itemize}
        \item \underline{Cold start miss:} Tritt auf beim ersten Zugriff auf einen Block nach dem Start des Programms oder dem Task-Wechsel (auch bei unendlich großem Cache)
        \item \underline{Capacity miss:} Tritt auf, wenn der Cache nicht alle Blocks speichern kann, die bei der Ausführung durch die CPU benötigt werden (nur bei fully associative Cache)
        \item \underline{Conflict miss:} Tritt auf, wenn ein Block ersetzt werden muß, der anschließend wieder benötigt wird (bei N-way associative Cache)
        \item \underline{Coherence miss:} bei Mehrprozessorsystemen → wird später erklärt
    \end{itemize}
\end{defi}

\begin{defi}[Reduzierung der Cache Miss Rate]{Programmierstrategien}
    Verbessern der Speicherlokalität durch
    \begin{itemize}[\ldots]
        \item Datenstrukturierung
        \item Ändern der Indexierung
        \item Schleifenfusion
        \item Bildung von Teilblöcken
    \end{itemize}
\end{defi}

\begin{defi}{Table-Look-Aside Buffer}
    Bei Rechnern mit virtueller Speicherverwaltung arbeitet der Prozessor mit virtuellen Adressen, 
    die durch den TLB in reale Adressen umgesetzt werden.
\end{defi}

\subsection{Entwicklungslinien der Prozessoren}\label{subsec:entwicklungslinien-der-prozessoren}

\begin{defi}{Complex Instruction Set Computer (CISC)}
    Befehls-Code ist Index auf Zeiger-Array für Mikroprogramm,
    die Hardware führt die Sequenz der Mikrobefehle aus.
\end{defi}

\begin{defi}{Reduced Instruction Set Computer (RISC)}
    Der Compiler erzeugt direkt \enquote{Mikrobefehle}. 
    Es muss zwar mehr Code erzeugt werden, 
    aber die Hardware wird einfacher und damit auch schneller.
\end{defi}

\begin{defi}{Very Long Instruction Word (VLIW)}
\end{defi}

\begin{defi}{Explicitly Parallel Instruction Computing (EPIC)}
    Von HP und Intel wurde 1998/99 die Prozessorarchitektur EPIC entworfen 
    und mit dem Intel Itanium ein erster Prozessor realisiert. 
    Die Intel-Version der Architektur wird IA-64 (64 bit) genannt.
    
    EPIC ist die moderne Weiterentwicklung des Konzepts des VLIW.
    
    Hierbei versucht der Compiler, 
    möglichst viele voneinander unabhängige Instruktionen in einer Sequenz zusammenzustellen. 
    Er kann dabei durch Umstellen der Befehle die Reihenfolge innerhalb der Sequenz verändern. 
    Dies darf aber nicht zu anderen Ergebnissen führen!
    
    Eine solche Sequenz nennt Intel ein “bundle”.
\end{defi}